{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19824e19",
   "metadata": {},
   "source": [
    "# Loading and testing pre-trained models\n",
    "Within `maltorch` it is possible to load pre-trained models and test them right away.\n",
    "The code to be written is minimal, since **all** the included models provide pre-trained weights that can be downloaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74fef31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "try:\n",
    "    import maltorch\n",
    "except ImportError:\n",
    "   %pip install git+https://github.com/zangobot/maltorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2f9b4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from maltorch.data.loader import load_from_folder, create_labels\n",
    "from maltorch.data_processing.grayscale_preprocessing import GrayscalePreprocessing\n",
    "from maltorch.zoo.avaststyleconv import AvastStyleConv\n",
    "from maltorch.zoo.bbdnn import BBDnn\n",
    "from maltorch.zoo.ember_gbdt import EmberGBDT\n",
    "from maltorch.zoo.malconv import MalConv\n",
    "from maltorch.zoo.resnet18 import ResNet18\n",
    "\n",
    "# To properly work, we need some PE test data \n",
    "# that you can insert inside a \"data\" folder located in the tutorial directory.\n",
    "exe_folder = Path(\"insert_here_path\")\n",
    "\n",
    "# We now instantiate the AI-based Windows malware detector we want to evaluate.\n",
    "# All the parameters of the networks are fetched online, \n",
    "# since we are not passing the model_path into the create_model function.\n",
    "# It is possible also to define which device to use while loading them,\n",
    "# as all Pytorch-based models can be run in GPU.\n",
    "\n",
    "device = \"cpu\"\n",
    "networks = {\n",
    "    'EMBER GBDT': EmberGBDT.create_model(),\n",
    "    'BBDnn': BBDnn.create_model(device=device),\n",
    "    'Malconv': MalConv.create_model(device=device),\n",
    "    'AvastStyleConv': AvastStyleConv.create_model(device=device),\n",
    "    'Grayscale ResNet18': ResNet18.create_model(\n",
    "        preprocessing=GrayscalePreprocessing(),\n",
    "        device=device),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae8d40a9",
   "metadata": {},
   "source": [
    "As shown in the code, all models are instantiated through a `create_model` function, which also accepts parameters to tune the internals of the AI-based detector to instantiate.\n",
    "Also, we can notice that the ResNet18, which is a CNN that preprocess each PE as an image, is loaded with a Grayscale Preprocessing.\n",
    "This object acts as a feature extractor, since it will convert all input PEs to grayscale images before computing predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7c5171f",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "received an empty list of sequences",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DataLoader, TensorDataset\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# We now load all .exe file from the folder, and we load them \u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# on the same device as the models.\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# All data are used as Pytorch dataloaders, \u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# so that inference can be computed in batch (if the model allows it).\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m X = \u001b[43mload_from_folder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexe_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mexe\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m y = create_labels(X, \u001b[32m1\u001b[39m)\n\u001b[32m     10\u001b[39m data_loader = DataLoader(TensorDataset(X, y), batch_size=\u001b[32m3\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Repositories/maltorch/src/maltorch/data/loader.py:28\u001b[39m, in \u001b[36mload_from_folder\u001b[39m\u001b[34m(path, extension, padding, limit, device)\u001b[39m\n\u001b[32m     26\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m limit \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(X) >= limit:\n\u001b[32m     27\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m X = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mutils\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrnn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpad_sequence\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m)\u001b[49m.transpose(\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m).long()\n\u001b[32m     29\u001b[39m X = X.to(device)\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m X\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/maltorch/lib/python3.12/site-packages/torch/nn/utils/rnn.py:481\u001b[39m, in \u001b[36mpad_sequence\u001b[39m\u001b[34m(sequences, batch_first, padding_value, padding_side)\u001b[39m\n\u001b[32m    477\u001b[39m         sequences = sequences.unbind(\u001b[32m0\u001b[39m)  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n\u001b[32m    479\u001b[39m \u001b[38;5;66;03m# assuming trailing dimensions and type of all the Tensors\u001b[39;00m\n\u001b[32m    480\u001b[39m \u001b[38;5;66;03m# in sequences are same and fetching those from sequences[0]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m481\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_C\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_nn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpad_sequence\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    482\u001b[39m \u001b[43m    \u001b[49m\u001b[43msequences\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_first\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_side\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[32m    483\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: received an empty list of sequences"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# We now load all .exe file from the folder, and we load them \n",
    "# on the same device as the models.\n",
    "# All data are used as Pytorch dataloaders, \n",
    "# so that inference can be computed in batch (if the model allows it).\n",
    "\n",
    "X = load_from_folder(exe_folder, \"exe\", device=device)\n",
    "y = create_labels(X, 1)\n",
    "data_loader = DataLoader(TensorDataset(X, y), batch_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f879adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from secmlt.metrics.classification import Accuracy\n",
    "\n",
    "# We can now compute all predictions!\n",
    "# We just invoke the model as a Pytorch function, which returns a dataloader of labels.\n",
    "# This is fed to the Accuracy object, which computes the performance on these data.\n",
    "\n",
    "print(\"Computing maliciousness of loaded data...\")\n",
    "for k in networks:\n",
    "    model = networks[k]\n",
    "    print(f\"{k}: {Accuracy()(model, data_loader) * 100:.2f}% malicious\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6c82ed",
   "metadata": {},
   "source": [
    "## What's inside a model?\n",
    "\n",
    "We have seen how to load a pre-trained model.\n",
    "But how to create a new one? It is very easy in fact:\n",
    "* if it is a generic Pytorch mode, you need to extend the `BaseModel` class \n",
    "* if it is a Pytorch model that requires an Embedding Layer, you need to extend the `EmbeddingModel` class\n",
    "* if it is not a Pytorch model, you need to extend the `Model` class and provide the mappings to the underlaying non-Pytorch data structures\n",
    "\n",
    "While `Model` and `EmbeddingModel` are provided within `maltorch` (`maltorch.zoo.model`), the `BaseModel` is provided by the supporting library `secml-torch` (`secmlt.models.base_model`).\n",
    "\n",
    "Below an example for creating your own `EmbeddingModel`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62112415",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from maltorch.zoo.model import EmbeddingModel\n",
    "\n",
    "# Init should contain the parameters to define your model, provide the defaults you wish to use\n",
    "class YourNewEmbeddingModel(EmbeddingModel):\n",
    "    def __init__(\n",
    "            self,\n",
    "            embedding_size: int = 8,\n",
    "            min_len: int = 4096,\n",
    "            max_len: int = 102400,\n",
    "            threshold: float = 0.5,\n",
    "            padding_idx: int = 256,\n",
    "    ):\n",
    "        super(BBDnn, self).__init__(name=\"model_name\", gdrive_id=\"gdrive_id\", min_len=min_len, max_len=max_len)\n",
    "        self.max_len = max_len\n",
    "        self.threshold = threshold\n",
    "        self.embedding = torch.nn.Embedding(\n",
    "            num_embeddings=257, embedding_dim=embedding_size, padding_idx=padding_idx\n",
    "        )\n",
    "        # Insert here Pytorch model definition\n",
    "        \n",
    "\n",
    "    # Must define function for returning the embedding layer\n",
    "    def embedding_layer(self):\n",
    "        return self.embedding\n",
    "\n",
    "    # Must define the logic AFTER the embedding\n",
    "    def _forward_embed_x(self, x):\n",
    "        #insert here your Pytorch logic\n",
    "        return x\n",
    "\n",
    "    # Must define how embeddings are computed\n",
    "    def embed(self, x):\n",
    "        emb_x = self.embedding(x)\n",
    "        emb_x = emb_x.transpose(1, 2)\n",
    "        return emb_x\n",
    "\n",
    "    # Must define a get function for retrieving the weights of embeddings\n",
    "    def embedding_matrix(self):\n",
    "        return self.embedding.weight\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "maltorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}